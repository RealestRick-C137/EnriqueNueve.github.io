<!DOCTYPE HTML>
<!--
	Read Only by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>

<head>
	<title>Enrique Nueve Blog</title>
	<meta charset="utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
	<link rel="stylesheet" href="assets/css/main.css" />
</head>

<body class="is-preload">

	<!-- Header -->
	<section id="header">
		<header>
			<span class="image avatar"><img src="images/me_pic.jpg" alt="" /></span>
			<h1 id="logo"><a href="index.html">Enrique Nueve</a></h1>
			<p>ML Engineer and Aspiring Researcher</p>
		</header>
		<nav id="nav">
			<ul>
				<li><a href="index.html" class="active">Home</a></li>

			</ul>
		</nav>
		<footer>
			<ul class="icons">
				<li><a href="https://github.com/EnriqueNueve" class="icon brands fa-github"><span class="label">Github</span></a></li>
				<li><a href="https://www.linkedin.com/in/enrique-nueve-7a050115b/" class="icon brands fa-linkedin"><span class="label">linkedin</span></a></li>
			</ul>
		</footer>
	</section>

	<!-- Wrapper -->
	<div id="wrapper">

		<!-- Main -->
		<div id="main">

			<!-- One -->
			<section id="one">
				<div class="image main" data-position="center">
					<img src="images/chicago_banner.jpg" alt="" />
				</div>
				<div class="container">
					<header class="major">
						<h2>WeatherNet: Nowcasting Net Radiation over the Edge</h2>
						<p> Summer 2020</p>
					</header>

					<br></br>
					<h3> Prologue</h3>
					<p> &emsp; In the summer of 2020, I was fortunate enough to be able to get a position
						as an intern as a Machine Learning Engineer at Argonne National Laboratory.
						I worked on the SAGE team whose task is
						to design a cyberinfrastructure for AI over Edge Computing. This blog is a high-level
						(I mean high-high level) overview of the research I did over the summer of 2020.
						Currently, a poster on this project has been accepted to the American Meteorigoal Society's
						20th Conference on Artificial Intelligence for Environmental Science and as a long paper to
						IEEE Conference on Technologies for Sustainability (SusTech 2021). This is my first
						work I have had accepted for publication as the primary author. In this post, I cover some of the findings
						from this work and also discuss the research/application process.
						To learn more about the SAGE project, please visit their <a href="https://sagecontinuum.org/">website.</a>
					</p>

					<h3> Intro </h3>
					<p> &emsp; Back in December 2020, I emailed a researcher at Argonne National Laboratory about a problem I was
						stuck on that they might have insight on given their research expertise. Although the person was not able to
						directly guide me for this problem, they suggested to me to apply to Argonne for an internship over the summer.
						This was my senior year of college, and in previous years I was unable to secure a summer internship. Being that for
						my first two years I went to community college, I assumed I didn't stand out much in my applications (free to play,
						pay to win). During my junior year summer, I tried applying and had a few email exchanges, but they led nowhere. Not
						being able to get an internship in the past made my eary of my chances of getting a position yet I still applied. Luckily,
						I was accepted onto the SAGE project, an initiative to design
						a cyberinfrastructure for AI over Edge Computing. I didn't even know what Edge Computing at the time was yet, I
						I was just happy to be able to have an official position where I was going to do work in Machine Learning. Given that
						COVID-19 was occurring (and still at this time), the position was conducted virtually.
					</p>
					<p> &emsp;At the time of starting, the SAGE project was still in quite early stages. The project leads wanted me and
						the other interns to make up Machine Learning projects that could be run on their Edge devices to act as show
						pieces for users of the future Edge network possible things they could do with it. I was given access to
						an Edge node that had three cameras connected to it: a sky facing RGB camera, a horizon facing RGB camera, and a
						FLIR camera (a camera that can pick up heat). With those three cameras, they asked me to come up with an application
						that used multiple cameras in order to demonstrate how multiple sensors from a node could be used for an application.
						With not knowing what to do (as usual), I came up with the idea of performing weather forecasting using the images from the cameras
						along with data collected from a weather tower located on the Argonne property. In particular, I came up with the idea
						of nowcasting net radiation using the camera images and weather tower data over an Edge node.
					</p>

					<h3>What is Nowcasting?</h3>
					<p> &emsp; Nowcasting is the task of weather forecasting within a horizon period of twenty-four hours.<sup>3</sup>
						By being able to accurately nowcast, abrupt weather changes can be announced earlier. Nowcasting can allow people
						to have the needed time to prepare for weather-related dangers such as hail, thunder, or tornados. Nowcasting
						 can also provide the needed detailed information to optimize industrial tasks such as photovoltaic management
						  and solar thermal collection.
				 </p>

					<h3>Nowcasting and Deep Learning</h3>
					<p>
					&emsp; Traditionally, nowcasting is performed by Numerical Weather Prediction (NWP) models that use radar data. However,
					recently, many scientists have developed ways to conduct nowcasting using Deep Learning and have achieved great success.
					As of March 2020, Google Research released a paper documenting a Deep Learning model that performs nowcasting called MetNet.<sup>1</sup>
					MetNet was able to outperform the High-Resolution Rapid Refresh (HRRR) system, the state of the art NWP method available from
					NOAA (the National Oceanic and Atmospheric Administration) for precipitation forecasting within a 7-8 hour window. Both NWP models and
					Deep Learning nowcasting models use radar data as input. Radar data does provide powerful insight into macro
					atmospheric activity. However, I hypothesize that adding data from ground-based sensors to nowcasting models could improve nowcasting
					for precise locations. To be able to accurately nowcast for a precise location, it is reasonable to assume that information about the site is
					needed- which is not provided through traditional radar data.
					</p>
					<p>
					&emsp; To explore the plausibility of using ground-based sensor data to enhance the performance of a nowcasting model,
					I sought out to develop a rudimentary experiment that would provide insight into my hypothesis. I desired to construct a
					Deep Learning model that only used ground-based sensor data to perform nowcasting. The reasoning was that if I was
					able to perform nowcasting using only ground-based sensor data (which is unique from radar data), then
					it would be plausible that combining ground-based sensor data with radar data could create a more
					powerful model. Vice-versa, if a Deep Learning model that only used ground-based sensor data could
					not perform nowcasting to any degree, it would be unlogical to assume that combining ground-based
					sensor data and radar data would improve a model's ability to nowcast- thus voiding my hypothesis's plausibility.
					</p>


					<h3>Data Management with SAGE</h3>
					<p> &emsp; For my experiment, I employed SAGE, a Cyber infrastructure for AI at the Edge.
						SAGE allowed me to access a weather tower and a node with a ground-based camera system,
						located on the Argonne National Laboratory campus, with ease to harvest data. The weather
						tower collected the following metadata: wind speed, wind direction, precipitation, heat flux, irradiation, net radiation,
						vapor pressure, and dew point temperature. The camera system
						consisted of three cameras: a sky facing RGB camera, a horizon-facing RGB camera, and
						an infrared (FLIR) camera. Through the ground-based weather sensors and cameras, I was
						able to collect a dataset for my desired experiment.
					</p>

					<figure>
					<img src="images/node_images.jpg" class="image fit"/>
					<figcaption> Images from Cameras </figcaption>
				  </figure>
					<p></p>

					<p>
					&emsp; Upon collecting the data, I restructured the data into fifteen-minute samples. Then the data
					was separated into four-element tuples consisting of data samples from an hour at 00, 15, 30,
					and 45 minutes. For my experiment, I decided to nowcast net radiation. Net radiation is
					the difference between incoming solar radiation absorbed by the Earth's surface and the radiation
					reflected back into space.<sup>2</sup> Thus, my model's input data was four samples from the previous
					hour consisting of images from each camera and weather sensor data, while my model's prediction value was
					a future period's net radiation amount.
					<p/>


					<h3>WeatherNet</h3>
					<p> &emsp; With the data consisting of images from the camera and tabular data from the weather sensors in the
						 form of a time-series, the Deep Learning model used was a Convolutional LSTM variant, named WeatherNet.
						  Convolutional LSTM's allow images in the form of time series to be used as input and can learn the temporal
							relationships between the images. This allowed WeatherNet to learn changes in the weather over time from
							the camera's images.<sup>4</sup> I also incopraated Seperable Convolutional layers wrapped in Time
							Distributed layers for each of the camera's input before feeding in to the Convolutional LSTM layers.
							This was done since Convolutional LSTM layers use a large amount of parameters relative to their input,
							and given that I wanted this run on a remote Edge device, I needed to decrease the number of parameters.
							Through using the Separable Convolutional layers wrapped in Time Distributed layers, I was able to
							decrease the number of parameters but also preserve information about the time relationships between the images.
							By further modifying the traditional Convolutional LSTM, WeatherNet
							was also able to take as input, not just images, but also the tabular weather sensor data. WeatherNet
							was then trained to nowcast net radiation for 15, 30, 60, 75, and 90 minute horizon periods.
					</p>


					<figure>
					<img src="images/weathernet_banner.png" class="image fit"/>
					<figcaption> Diagram of WeatherNet</figcaption>
				  </figure>
					<p></p>

					<h3>Experiments</h3>

					<p>
					&emsp; To test the informativeness of the ground- based sensor data for the task of nowcasting net radiation, three experiments were conducted.
					<ol>
					  <li>Nowcasting Net Radiation with Weather Sensor Data</li>
					  <li>Nowcasting Net Radiation with Ground- Based Camera Data</li>
					  <li>Nowcasting Net Radiation with Weather Sensors and Ground-Based Camera Data</li>
					</ol>
					These three experiments performed nowcasting of net radiation for a 15, 30, 45, 60, 75, and 90-minute horizon.
					Data was collected from January to June of 2020 from the previously mentioned ground-based sensors, located on the
					property of Argonne National Laboratory. The data from January to May was used to train the models,
					while June's data was used for testing. The cumulative MSE and R2 for each experiment for different horizons
					can be viewed in the plots below.
					</p>

					<figure>
					<img src="images/wn_mse_plot.jpg" class="image fit"/>
					<figcaption>Experiments MSE results</figcaption>
					</figure>
					<p></p>


					<figure>
					<img src="images/wn_r2_plot.jpg" class="image fit"/>
					<figcaption>Experiments R2 results</figcaption>
					</figure>
					<p></p>




					<h3>Reflection and Conclusion</h3>
					<p>
					&emsp; The results of the experiment were modest. By no means do these results suggest to
					replace traditional nowcasting that uses radar data with this method. However, given the
					uniqueness of the data and that the results suggest that there is a moderately informative
					signal, to try nowcasting using radar data with also the ground-based sensor data.
					Upon completing the initial experiments in August 2020, I continued to write and
					re-conduct experiments over and over and over again. I found out that research never
					really ends; you eventually just stop working on the problem.
					</p>
					<p>
					&emsp; During my junior and senior year, I worked as a research assistant (a.k.a my professors would
					give my hopeless projects they didn't have time for). During those two years, I personally didn't publish once.
					This work went on to become an accepted paper at IEEE SusTech 2021 where I will be presenting in April 2021 and
					also as a poster at the American Meteorigoal Society's 20th Conference on Artificial Intelligence for Environmental Science.
					This work by no means is groundbreaking yet, from a career standpoint, this meant a lot given that I had worked
					as a research assistant for two years (given, I was an undergraduate) without anything to show.
					</p>
					<p>
					&emsp; Although I have not made a great conceptual breakthrough, I desire that could produce a paper worthy of an
					elite conference I desire, I am seeing progress. I am becoming more self-aware of my shortcomings, scheduling,
			 		questioning methods, etc. All of these skills have been developed through my years as a research assistant where I had no results.
					To summarize, I am starting to learn that perseverance is more than just an idea on a card. Tenacity may be the deciding
					 factor between success and failure. Potentially going to graduate school in the Fall of 2021, I hope to take these
					developed skills to perform research in the future and do find that great conceptual breakthrough I desire.
					</p>


					<h3>Reference</h3>
					<p>
						[1] Casper Kaae Sønderby et al.MetNet: A Neural Weather  Model  for  Precipitation  Forecasting.2020. arXiv:2003.12140 [cs.LG]. <br>
						[2] StoryMapJournal.URL:https://www.arcgis.com/apps/MapJournal/index.html?appid=93ed895dfa3343eb9b821a2933decdd8. <br>
						[3] Yong  Wang  et  al.Guidelines  for  Nowcasting Techniques. Nov. 2017.ISBN: 978-92-63-11198-2 <br>
						[4] Xingjian  Shi  et  al.Convolutional  LSTM  Net-work:  A  Machine  Learning  Approach  for
						    Pre-cipitation   Nowcasting.   2015.   arXiv:1506 .04214 [cs.CV]. <br>
					</p>



				</div>
			</section>
		</div>

		<!-- Footer -->
		<section id="footer">
			<div class="container">
				<ul class="copyright">
					<li>&copy; Untitled. All rights reserved.</li>
					<li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
				</ul>
			</div>
		</section>

	</div>

	<!-- Scripts -->
	<script src="assets/js/jquery.min.js"></script>
	<script src="assets/js/jquery.scrollex.min.js"></script>
	<script src="assets/js/jquery.scrolly.min.js"></script>
	<script src="assets/js/browser.min.js"></script>
	<script src="assets/js/breakpoints.min.js"></script>
	<script src="assets/js/util.js"></script>
	<script src="assets/js/main.js"></script>

</body>

</html>
